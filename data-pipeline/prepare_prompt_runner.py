#!/usr/bin/env python3
"""Load a prompt bank and turn it into structured chains for automation."""

from __future__ import annotations

import argparse
import json
import os
import random
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Sequence

PROMPT_BANK_DEFAULT = Path(__file__).resolve().parent.parent / "prompt_bank.json"

@dataclass
class PreparedPrompt:
    chain_id: int
    category: str
    model: str
    step_index: int
    text: str

    def to_dict(self) -> dict:
        return {
            "chain_id": self.chain_id,
            "category": self.category,
            "model": self.model,
            "step": self.step_index,
            "text": self.text,
        }


def parse_arguments() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Load a prompt bank and shape the chains for future automation."
    )
    parser.add_argument(
        "--prompt-bank",
        dest="prompt_bank",
        type=Path,
        default=PROMPT_BANK_DEFAULT,
        help="Path to the prompt bank JSON file generated by generate_prompt_bank.py.",
    )
    parser.add_argument(
        "--max-chains",
        type=int,
        default=None,
        help="If provided, only the first N chains (after optional filtering) are prepared.",
    )
    parser.add_argument(
        "--categories",
        nargs="+",
        default=None,
        help="Filter to chains whose category matches one of these values (case-insensitive).",
    )
    parser.add_argument(
        "--shuffle",
        action="store_true",
        help="Randomize the order of chains before slicing with --max-chains.",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("prepared_prompt_plan.json"),
        help="Where to write the prepared prompt plan for later automation.",
    )
    return parser.parse_args()


def load_prompt_bank(path: Path) -> list[dict]:
    if not path.exists():
        raise FileNotFoundError(f"Prompt bank not found at {path}")

    with path.open("r", encoding="utf-8") as reader:
        data = json.load(reader)

    if not isinstance(data, list):
        raise ValueError("Prompt bank must contain a list of prompt-chain entries.")

    return data


def filter_and_order_chains(
    prompt_bank: Sequence[dict], *, categories: Sequence[str] | None, shuffle: bool, max_chains: int | None
) -> list[dict]:
    normalized_categories = {cat.lower() for cat in categories} if categories else None

    chains = []
    for entry in prompt_bank:
        category = entry.get("category", "uncategorized")
        if normalized_categories and category.lower() not in normalized_categories:
            continue
        chains.append(entry)

    if shuffle:
        random.shuffle(chains)

    if max_chains is not None:
        chains = chains[: max_chains]

    return chains


def build_prepared_prompts(chains: Iterable[dict]) -> list[PreparedPrompt]:
    prepared: list[PreparedPrompt] = []
    for chain_id, entry in enumerate(chains, start=1):
        prompts = entry.get("prompts", [])
        category = entry.get("category", "uncategorized")
        model = entry.get("model", "unknown")
        for step_index, text in enumerate(prompts, start=1):
            if not isinstance(text, str):
                text = str(text)
            prepared.append(PreparedPrompt(chain_id, category, model, step_index, text))
    return prepared


def main() -> None:
    args = parse_arguments()
    prompt_bank = load_prompt_bank(args.prompt_bank)

    chains = filter_and_order_chains(
        prompt_bank,
        categories=args.categories,
        shuffle=args.shuffle,
        max_chains=args.max_chains,
    )

    prepared_prompts = build_prepared_prompts(chains)

    # Sample OpenAI API query loop (not final, for future browser LLM integration)
    import requests
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "sk-...YOUR_KEY...")
    OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"

    for prepared in prepared_prompts:
        payload = {
            "model": prepared.model,
            "messages": [
                {"role": "user", "content": prepared.text}
            ],
            "max_tokens": 256
        }
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        print(f"Querying OpenAI for chain {prepared.chain_id}, step {prepared.step_index}...")
        try:
            response = requests.post(OPENAI_API_URL, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()
            print("Response:", result.get("choices", [{}])[0].get("message", {}).get("content", "No content"))
        except Exception as e:
            print(f"Error querying OpenAI: {e}")

    print(f"Queried {len(prepared_prompts)} prompt steps from {len(chains)} chains.")


if __name__ == "__main__":
    main()

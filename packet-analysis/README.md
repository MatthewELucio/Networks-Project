# Packet Analysis - LLM Traffic Classification

This directory contains all the machine learning models, analysis scripts, and results for classifying network flowlets as LLM (ChatGPT) vs non-LLM traffic.

## Directory Contents

### Python Scripts
- **`flowlet_models.py`** - Train classification models (Random Forest, SVM, XGBoost) using MaMPF-inspired features
- **`flowlet_analysis.py`** - Analyze feature importance, correlations, and distributions

### Results & Reports
- **`model_results.json`** - Detailed classification metrics for all three models
- **`MODEL_SUMMARY.md`** - Comprehensive summary of model performance and methodology
- **`analysis_results.json`** - Feature analysis results (correlations, importance, statistical tests)
- **`FEATURE_ANALYSIS_SUMMARY.md`** - Detailed feature analysis findings and recommendations

### Visualizations (`analysis_plots/`)
- **`correlation_heatmap.png`** - Feature correlation matrix heatmap
- **`feature_importance.png`** - Feature importance comparison (RF vs XGBoost)
- **`feature_distributions.png`** - Distribution comparisons (LLM vs non-LLM)
- **`target_correlations.png`** - Feature correlations with LLM label

## Quick Start

### 1. Train Classification Models
```bash
python flowlet_models.py ../flowlet_features.json --output model_results.json
```

**Input**: `flowlet_features.json` (generated by `parse_flowlets.py --extract-features`)

**Output**: 
- `model_results.json` - Model performance metrics
- Console output with accuracy, precision, recall, F1 scores

### 2. Analyze Features
```bash
python flowlet_analysis.py ../flowlet_features.json --output analysis_results.json --output-dir analysis_plots
```

**Input**: `flowlet_features.json`

**Output**:
- `analysis_results.json` - Statistical analysis results
- `analysis_plots/` - Visualization plots
- Console output with key findings

## Model Performance Summary

| Model | Accuracy | Precision | Recall | F1 Score |
|-------|----------|-----------|--------|----------|
| **Random Forest** | **95.04%** | **98.03%** | 59.23% | 73.85% |
| SVM | 94.63% | 93.78% | 58.46% | 72.02% |
| **XGBoost** | **95.00%** | **97.77%** | 59.08% | 73.65% |

**Key Characteristics**:
- High precision (>97%) - Very few false positives
- Moderate recall (~59%) - Some LLM traffic is missed
- Excellent for network monitoring where false alarms are costly

## Feature Importance

**Top 2 Features** (account for ~93% of classification power):
1. **`packet_size_mean`** (48.0% importance) - Average packet size
2. **`total_bytes`** (45.3% importance) - Total data transferred

**Why These Work**:
- LLM services stream responses â†’ larger packets
- LLM conversations involve more data exchange
- Non-LLM traffic has smaller, more uniform packets

## Dataset

- **Total flowlets**: 77,437 (ChatGPT + non-LLM)
- **LLM flowlets**: 5,299 (6.8%)
- **Non-LLM flowlets**: 72,138 (93.2%)
- **Train/Test split**: 80/20 by flow groups

## Features Used

### Statistical Features (7)
1. `duration` - Flowlet time span
2. `packet_count` - Number of packets
3. `total_bytes` - Total data transferred
4. `inter_packet_time_mean` - Average inter-packet gap
5. `inter_packet_time_std` - Std dev of inter-packet gaps
6. `packet_size_mean` - Average packet size
7. `packet_size_std` - Std dev of packet sizes

### MaMPF-Inspired Features (4)
8. LLM time-gap log-likelihood
9. LLM size-block log-likelihood
10. Non-LLM time-gap log-likelihood
11. Non-LLM size-block log-likelihood

## Dependencies

```bash
pip install numpy scikit-learn xgboost matplotlib seaborn scipy
```

See `../requirements.txt` for specific versions.

## Methodology

### MaMPF-Inspired Approach
Based on the paper "MaMPF: Encrypted Traffic Classification Based on Multi-Attribute Markov Probability Fingerprints"

1. **Time-gap bucketing**: Discretize inter-packet times into 4 states
2. **Power-law blocks**: Build representative packet size blocks (90% coverage)
3. **Markov models**: Train first-order chains for each class
4. **Fingerprints**: Compute log-likelihoods as features
5. **Traditional ML**: Train RF, SVM, XGBoost on combined features

### Group-Based Splitting
- Flows (same 5-tuple) stay together in train or test
- Prevents data leakage between splits
- More realistic evaluation

## Future Work

1. **Multi-class classification**: Extend to Claude, Gemini, other LLM providers
2. **Improve recall**: Address the ~41% false negative rate
3. **Feature engineering**: Add burst patterns, sequence features
4. **Real-time detection**: Optimize for streaming classification
5. **Address class imbalance**: Try SMOTE or class weighting

## References

- Input data: `../flowlet_features.json` (generated by `../parse_flowlets.py`)
- Capture files: `../captures/` (organized by LLM provider)
- Main parsing script: `../parse_flowlets.py`

## Contact

For questions about the analysis or models, refer to:
- `MODEL_SUMMARY.md` - Detailed model documentation
- `FEATURE_ANALYSIS_SUMMARY.md` - Feature analysis findings
